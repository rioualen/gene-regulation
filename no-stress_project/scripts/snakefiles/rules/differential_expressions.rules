rule edgeR:
    """Run differential expression analysis on a table of counts per tag
    (gene). 

    This rule takes as input a tab-delimited text file containing gene
    counts per sample (one row per gene, one column per sample) and a gene
    annotation file (gtf).

    Result files:

    1. A tab-delimited file with with differential expression
       statistics, sorted by significance (p-value of FDR).
    2. A pdf file with various plots. 

    """
    input: COUNT_FILES
    output: R_params = config["dir"]["data_root"] + "results/bowtie2_mm" + config["bowtie2"]["max_mismatches"] + "_sorted_" + config["htseq"]["order"] + "_params.R", \
            csv = COUNT_RESULTS, \
            all_counts_file = config["dir"]["data_root"] + "results/bowtie2_mm" + config["bowtie2"]["max_mismatches"] + "_sorted_" + config["htseq"]["order"] + "_allcounts.tab"
    # log: "results/{cond_1}_VS_{cond_2}_bowtie2_mm" + config["bowtie2"]["max_mismatches"] + "_sorted_" + config["htseq"]["order"] + ".log"
    # benchmark: "results/{cond_1}_VS_{cond_2}_bowtie2_mm" + config["bowtie2"]["max_mismatches"] + "_sorted_" + config["htseq"]["order"] + ".json"
    params: qsub = config["qsub"] + " -q short", \
            cond1 = config["edgeR"]["cond1"], cond2=config["edgeR"]["cond2"], \
            data_root = config["dir"]["data_root"]
    run:
        condition_1 = params.cond1
        condition_2 = params.cond2

        data_root = params.data_root


        gene_ids_ok = True
        list_line = []
        #Creating a count file with all replicates of all conditions
        for i in range(len(COUNT_FILES)):
            count_res = open(COUNT_FILES[i])
            #Check if gene_ids already exist 
            if gene_ids_ok:
                for line in count_res:
                    gene_counts_ids = line.split("\t")
                    list_line.append(gene_counts_ids[0] + "\t" + gene_counts_ids[1].strip("\n"))
                gene_ids_ok = False

            #If gene_ids already exist add count column
            list_file = count_res.readlines()
            for j in range(len(list_file)):
                gene_counts = list_file[j].split("\t")
                list_line[j] += "\t" + gene_counts[1].strip("\n")
            count_res.close()

        #Open and write in a file
        all_counts = open(output.all_counts_file, 'w')
        for elm in list_line:
            all_counts.write(elm + "\n")
        all_counts.close()


        # Initializing variables

        counts_f = []
        sample_condition_py = []
        sample_names_py = []
        conditions = []
        n_rep = []
        output_list = []

        #Get all parameters for all comparisons
        for i in range(len(condition_1)):

            cond_1 = condition_1[i]
            cond_2 = condition_2[i]
            output_list.append(data_root + "results/" + cond_1 + "_VS_" + cond_2 + "_bowtie2_mm" + config["bowtie2"]["max_mismatches"] + "_sorted_" + config["htseq"]["order"] + ".csv")
            

            #Get biological replicate list
            R_1 = config["edgeR"][cond_1]
            R_2 = config["edgeR"][cond_2]

            ext = "_bowtie2_mm" + config["bowtie2"]["max_mismatches"] + "_sorted_" + config["htseq"]["order"] + "_count.txt" 

            #Create complete path for count files
            files_list = []
            for elt in R_1:
                files_list.append('"' + config["dir"]["data_root"] + elt + "/" + elt + ext + '"')

            for elt in R_2:
                files_list.append('"' + config["dir"]["data_root"] + elt + "/" + elt + ext + '"')

            #Separate the count files in string
            counts_f.append("c(" + ', \n '.join(files_list) + ")")
            #Get the list of condition 
            sample_condition_temp = ("'" + cond_1 + "',") * len(R_1) + ("'" +cond_2 + "',") * len(R_2)
            #remove the last coma
            sample_condition_py.append("c(" +  sample_condition_temp[:-1] + ")")

            #get list of replicate
            sample_names_py.append("c('" + "','".join(R_1) + "','" + "','".join(R_2) + "')")

            #list of condition
            conditions.append("c('" + cond_1 + "','" + cond_2 + "')")

            if len(R_1) >= len(R_2):
                n_rep.append(str(len(R_2)))
            else:
                n_rep.append(str(len(R_1)))
        
        out_R=open(output.R_params, 'w')
        out_R.write("## Root path \n" \
        + "data.root <-'" +  config["dir"]["data_root"] + "' \n \n" \
        + "## Table containing the counts of reads per gene (rows) for each sample (columns)  \n" \
        + "all.counts.table <- '" + output.all_counts_file + "' \n \n" \
        + "## Description of the conditions \n" \
        + "conditions <- c('" + "','".join(config["edgeR"]["conditions"]) + "') \n" \
        + "n.rep <-c(" + ','.join(n_rep) + ")\n \n" \
        + "count.files <-c('" + "', \n '".join(COUNT_FILES) + "') \n \n \n"\
        + "################################################################ \n" \
        + "## Structure of the comparisons for edgeR \n \n" \
        + "comparisons <-list(" + ','.join(conditions) + ")\n" \
        + "comparisons.cond1 <-list('" + "','".join(condition_1) + "') \n" \
        + "comparsions.cond2 <-list('" + "','".join(condition_2) + "') \n" \
        + "counts.files.per.comparisons <- list(" + ', \n'.join(counts_f) + ")\n" \
        + "condition.per.comparisons <-list(" + ', \n '.join(sample_condition_py) + ")\n" \
        + "names.per.comparisons <-list(" +  ', \n '.join(sample_names_py) + ")\n \n" \
        + "## List of cvs files that will be created by edgeR \n" \
        + "output <-c('" + "', \n '".join(output_list) + "') \n \n" \
        + "#### END OF THE CONFIG FILE \n" \
        + "################################################################" \
        )     
        out_R.close()
        
        out_path = config["dir"]["data_root"] + "results/test.txt"

        for i in range(len(condition_1)):
            out_test = open(str(output_list[i]), 'w')
            out_test.write(output_list[i])
            out_test.close()


        # R("""
        # library("edgeR")
        # library("limma")

        # source("{output.R_params}")

        # # get data from counts files
        # counts = readDGE(counts.f)$counts

        # # Remove summary lines from HTseq files
        # noint = rownames(counts) %in% c("no_feature","ambiguous","too_low_aQual", "not_aligned","alignment_not_unique")
        
        # # Remove all features that have less than 1 reads per millions of reads
        # cpms = cpm(counts)
        # keep = rowSums(cpms > 1) >= n.rep & !noint
        # counts = counts[keep,]

        # #tables preparation
        # colnames(counts) = xp.name
        
        # d = DGEList(counts=counts, group=xp.condition)
        # d = calcNormFactors(d)
        
        # pdf(file=paste(data.root, "/results/plotMDS_", cond1, "_VS_", cond2, ".pdf", sep="")) 
        # plotMDS(d, labels=xp.name, col=c("darkgreen","blue")[factor(xp.condition)])
        # dev.off()
        
        # d = estimateCommonDisp(d)
        # d = estimateTagwiseDisp(d)
        
        # pdf(file= paste(data.root, "/results/plotMeanVar_", cond1, "_VS_", cond2, ".pdf", sep=""))
        # plotMeanVar(d, show.tagwise.vars=TRUE, NBline=TRUE)
        # dev.off()

        # pdf(file= paste(data.root, "/results/plotBCV_", cond1, "_VS_", cond2, ".pdf", sep=""))
        # plotBCV(d)
        # dev.off()

        # #Differential expression
        # de = exactTest(d, pair=c(xp.list))

        # #tabular summary of the DE stats
        # tt = topTags(de, n=nrow(d))

        # nc = cpm(d, normalized.lib.sizes=TRUE)
        # rn = rownames(tt$table)

        # deg = rn[tt$table$FDR < .05]

        # pdf(file=paste(data.root, "/results/plotSmear_", cond1, "_VS_", cond2, ".pdf", sep=""))
        # plotSmear(d, de.tags=deg)
        # dev.off()

        # write.csv(tt$table, file=output)
        
        # """)